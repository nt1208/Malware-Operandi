import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.ensemble import VotingClassifier
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.svm import SVC
from sklearn.ensemble import AdaBoostClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import cross_val_score
from sklearn.metrics import classification_report
from per_vectors import *
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import precision_score, recall_score, f1_score
from sklearn.metrics import accuracy_score
import numpy as np
import re
import csv
import os
import chardet
import subprocess
import xml.etree.ElementTree as ET

def custom_tokenizer(text):
    email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
    ip_pattern = r'\b(?:\d{1,3}\.){3}\d{1,3}\b'
    url_pattern = r'https?://\S+\b'
    pattern = re.compile(f'({email_pattern})|({ip_pattern})|({url_pattern})|\w+')
    tokens = pattern.findall(text)
    tokens = [token for sublist in tokens for token in sublist if token != '']
    return tokens

def decompile_apk(apk_path, output_directory):
    output_path = f"/home/kali/NT230/RansomwareAndroid/DecompileApk/{output_directory}"
    subprocess.run(["apktool", "d", apk_path, "-o" , output_path, "-f"], check=True)

def extract_permissions(manifest_path):
    permissions = []
    try:
        manifest = ET.parse(manifest_path)
        root = manifest.getroot()
        for perm in root.findall('uses-permission'):
            permission_name = perm.get('{http://schemas.android.com/apk/res/android}name')
            permissions.append(permission_name)
    except Exception as e:
        print(f"Error extracting permissions from {manifest_path}: {e}")
    return permissions
    
def extract_text_features(output_directory):
    try:
        output = subprocess.check_output(['grep', '-rE', 'crypto|Cipher|cipher|wake|lock|locker', output_directory])
        return extract_important_info_text(output.decode())  # Trả về chuỗi đầy đủ từ kết quả grep
    except Exception as e:
        print(f"Error extracting text features: {e}")
        return ""  # Trả về chuỗi rỗng nếu có lỗi

def extract_important_info_text(grep_output):
    important_info = []
    lines = grep_output.splitlines()
    for line in lines:
        # Sử dụng biểu thức chính quy để lọc ra phần bạn quan tâm
        match = re.search(r'(?<=:)(.*?);', line)
        if match:
            important_info.append(match.group())
    return important_info
    
def extract_important_info(grep_output):
    important_info = []
    lines = grep_output.splitlines()
    seen = set()
    for line in lines:
        # Tìm các chuỗi URL, địa chỉ IP, email trong dòng
        matches = re.findall(r'https?://[^\s]+|[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+|[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}', line)
        for match in matches:
            if match not in seen:
                seen.add(match)
                important_info.append((match))
    return important_info

def extract_network_features(output_directory):
    try:
        grep_command = [
            'grep', '-rE',
            'https?://|[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+|[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}',
            output_directory
        ]
        output = subprocess.run(grep_command, capture_output=True, text=True)
        important_info = extract_important_info(output.stdout)
        return important_info
    except Exception as e:
        print(f"Error extracting network features: {e}")
        return "Loi"

def process_apk(apk_path):
    try:
        apk_name = os.path.basename(apk_path)  # Lấy tên thư mục từ đường dẫn
        output_directory = apk_name + ".out"
        output_path = f"/home/kali/NT230/RansomwareAndroid/DecompileApk/{output_directory}"
        decompile_apk(apk_path, output_directory)
        manifest_path = os.path.join(output_path, "AndroidManifest.xml")
        permissions = extract_permissions(manifest_path)
        network = extract_network_features(output_path)
        text_features = extract_text_features(output_path)
        return {
            'apk_name': apk_name,
            'permissions': permissions,
            'network': network,
            'text': text_features
        }
    except Exception as e:
        print(f"Error processing APK {apk_path}: {e}")
        return None

#------------------------QUA TRINH TRAINING DU LIEU--------------------------------------


#------------Statics------------------------
# Đọc các tệp vector từ các tệp CSV
permissions_df = pd.read_csv('/home/kali/NT230/RansomwareAndroid/feature vectors/permission_vectors.csv')
network_df = pd.read_csv('/home/kali/NT230/RansomwareAndroid/feature vectors/network_vectors.csv')
text_df = pd.read_csv('/home/kali/NT230/RansomwareAndroid/feature vectors/text_vectors.csv')

# Kết hợp các vector thành một DataFrame duy nhất
combined_df = permissions_df.join(network_df).join(text_df)
print(combined_df)
# Loại bỏ cột không cần thiết và xử lý giá trị NaN
X = combined_df.drop(columns=['Label'])
imputer = SimpleImputer(strategy='mean')
X_imputed = imputer.fit_transform(X)
y = combined_df['Label']

print(X)
print(X_imputed)
X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)
print(y_train)

#-------------Dynamics-------------------------
syscall_df = pd.read_csv('/home/kali/NT230/RansomwareAndroid/Dynamics/combined_feature_sys.csv')
memory_df = pd.read_csv('/home/kali/NT230/RansomwareAndroid/Dynamics/combined_feature_mem.csv')
# Kết hợp các vector thành một DataFrame duy nhất
dynamic_combined_df = pd.concat([syscall_df, memory_df], axis=1)
print(dynamic_combined_df)
# Loại bỏ cột không cần thiết và xử lý giá trị NaN
dynamic_X = dynamic_combined_df.drop(columns=['Label'])
dynamic_X_imputed = imputer.fit_transform(dynamic_X)
dynamic_y = dynamic_combined_df.iloc[:, -1]

print(dynamic_X)
print(dynamic_X_imputed)
print(dynamic_y)
dynamic_X_train, dynamic_X_test, dynamic_y_train, dynamic_y_test = train_test_split(dynamic_X_imputed, dynamic_y, test_size=0.2, random_state=42)
print(dynamic_y_train)

#------------------Ensemble-------------------------
#Ensemble 1 : C45 Decision tree, Random tree, Random forest
#clf1 = DecisionTreeClassifier()  
clf2 = DecisionTreeClassifier(splitter='random')  
clf3 = RandomForestClassifier(n_estimators=100)
voting1_clf = VotingClassifier(estimators=[('rt', clf2), ('rf', clf3) ], voting='soft')
voting1_clf.fit(X_train, y_train)
voting11_clf = VotingClassifier(estimators=[('rt', clf2), ('rf', clf3) ], voting='soft')
voting11_clf.fit(dynamic_X_train, dynamic_y_train)
static_pred1 = voting1_clf.predict(X_test)
accuracy1 = accuracy_score(y_test, static_pred1)
precision1 = precision_score(y_test, static_pred1)
recall1 = recall_score(y_test, static_pred1)
f11 = f1_score(y_test, static_pred1)
dynamic_pred1 = voting11_clf.predict(dynamic_X_test)
accuracy11 = accuracy_score(dynamic_y_test, dynamic_pred1)
precision11 = precision_score(dynamic_y_test, dynamic_pred1)
recall11 = recall_score(dynamic_y_test, dynamic_pred1)
f111 = f1_score(dynamic_y_test, dynamic_pred1)
print("Statics Ensembel 1")
print(f"Accuracy: {accuracy1:.2f}")
print(f"Precision: {precision1:.2f}")
print(f"Recall: {recall1:.2f}") 
print(f"F1-score: {f11:.2f}")
print("Dynamics Ensembel 1")
print(f"Accuracy: {accuracy11:.2f}")
print(f"Precision: {precision11:.2f}")
print(f"Recall: {recall11:.2f}") 
print(f"F1-score: {f111:.2f}")



#Ensemble 2 : Logistic regression, C45, SVM with SMO 
log_reg = LogisticRegression()
c45 = DecisionTreeClassifier()
svm_smo = SVC(kernel='linear', probability=True)  
voting2_clf = VotingClassifier(estimators=[('lr', log_reg), ('c45', c45), ('svm', svm_smo) ], voting='soft')
voting2_clf.fit(X_train, y_train)
voting22_clf = VotingClassifier(estimators=[('lr', log_reg), ('c45', c45), ('svm', svm_smo) ], voting='soft')
voting22_clf.fit(dynamic_X_train, dynamic_y_train)
static_pred2 = voting2_clf.predict(X_test)
accuracy2 = accuracy_score(y_test, static_pred2)
precision2 = precision_score(y_test, static_pred2)
recall2 = recall_score(y_test, static_pred2)
f12 = f1_score(y_test, static_pred2)
dynamic_pred2 = voting22_clf.predict(dynamic_X_test)
accuracy22 = accuracy_score(dynamic_y_test, dynamic_pred2)
precision22 = precision_score(dynamic_y_test, dynamic_pred2)
recall22 = recall_score(dynamic_y_test, dynamic_pred2)
f122 = f1_score(dynamic_y_test, dynamic_pred2)
print("Statics Ensembel 2")
print(f"Accuracy: {accuracy2:.2f}")
print(f"Precision: {precision2:.2f}")
print(f"Recall: {recall2:.2f}") 
print(f"F1-score: {f12:.2f}")
print("Dynamics Ensembel 2")
print(f"Accuracy: {accuracy22:.2f}")
print(f"Precision: {precision22:.2f}")
print(f"Recall: {recall22:.2f}") 
print(f"F1-score: {f122:.2f}")

#Ensemble 3 : Random tree, Random forest, SVM with SMO
#ran_tree = DecisionTreeClassifier(splitter='random') 
ran_forest = RandomForestClassifier()
voting3_clf = VotingClassifier(estimators=[('rf', ran_forest), ('svm', svm_smo) ], voting='soft')
voting3_clf.fit(X_train, y_train)
voting33_clf = VotingClassifier(estimators=[('rf', ran_forest), ('svm', svm_smo) ], voting='soft')
voting33_clf.fit(dynamic_X_train, dynamic_y_train)
static_pred3 = voting3_clf.predict(X_test)
accuracy3 = accuracy_score(y_test, static_pred3)
precision3 = precision_score(y_test, static_pred3)
recall3 = recall_score(y_test, static_pred3)
f13 = f1_score(y_test, static_pred3)
dynamic_pred3 = voting33_clf.predict(dynamic_X_test)
accuracy33 = accuracy_score(dynamic_y_test, dynamic_pred3)
precision33 = precision_score(dynamic_y_test, dynamic_pred3)
recall33 = recall_score(dynamic_y_test, dynamic_pred3)
f133 = f1_score(dynamic_y_test, dynamic_pred3)
print("Statics Ensembel 3")
print(f"Accuracy: {accuracy3:.2f}")
print(f"Precision: {precision3:.2f}")
print(f"Recall: {recall3:.2f}") 
print(f"F1-score: {f13:.2f}")
print("Dynamics Ensembel 3")
print(f"Accuracy: {accuracy33:.2f}")
print(f"Precision: {precision33:.2f}")
print(f"Recall: {recall33:.2f}") 
print(f"F1-score: {f133:.2f}")

#Ensemble 4 : SVM with SMO, Logistic regression, Random forest
voting4_clf = VotingClassifier(estimators=[('svm', svm_smo), ('lr', log_reg), ('rf', ran_forest) ], voting='soft')
voting4_clf.fit(X_train, y_train)
voting44_clf = VotingClassifier(estimators=[('svm', svm_smo), ('lr', log_reg), ('rf', ran_forest) ], voting='soft')
voting44_clf.fit(dynamic_X_train, dynamic_y_train)
static_pred4 = voting4_clf.predict(X_test)
accuracy4 = accuracy_score(y_test, static_pred4)
precision4 = precision_score(y_test, static_pred4)
recall4 = recall_score(y_test, static_pred4)
f14 = f1_score(y_test, static_pred4)
dynamic_pred4 = voting44_clf.predict(dynamic_X_test)
accuracy44 = accuracy_score(dynamic_y_test, dynamic_pred4)
precision44 = precision_score(dynamic_y_test, dynamic_pred4)
recall44 = recall_score(dynamic_y_test, dynamic_pred4)
f144 = f1_score(dynamic_y_test, dynamic_pred4)
print("Statics Ensembel 4")
print(f"Accuracy: {accuracy4:.2f}")
print(f"Precision: {precision4:.2f}")
print(f"Recall: {recall4:.2f}") 
print(f"F1-score: {f14:.2f}")
print("Dynamics Ensembel 4")
print(f"Accuracy: {accuracy44:.2f}")
print(f"Precision: {precision44:.2f}")
print(f"Recall: {recall44:.2f}") 
print(f"F1-score: {f144:.2f}")

#Ensemble 5 : SVM with SMO, Logistic regression, AdaBoost with SVM base
adaboost_model = AdaBoostClassifier(estimator=SVC(probability=True, kernel='linear'), n_estimators=50, algorithm='SAMME')
voting5_clf = VotingClassifier(estimators=[('svm', svm_smo), ('lr', log_reg), ('ab', adaboost_model) ],voting='soft')
voting5_clf.fit(X_train, y_train)
voting55_clf = VotingClassifier(estimators=[('svm', svm_smo), ('lr', log_reg), ('ab', adaboost_model) ],voting='soft')
voting55_clf.fit(dynamic_X_train, dynamic_y_train)
static_pred5 = voting5_clf.predict(X_test)
accuracy5 = accuracy_score(y_test, static_pred5)
precision5 = precision_score(y_test, static_pred5)
recall5 = recall_score(y_test, static_pred5)
f15 = f1_score(y_test, static_pred5)
dynamic_pred5 = voting55_clf.predict(dynamic_X_test)
accuracy55 = accuracy_score(dynamic_y_test, dynamic_pred5)
precision55 = precision_score(dynamic_y_test, dynamic_pred5)
recall55 = recall_score(dynamic_y_test, dynamic_pred5)
f155 = f1_score(dynamic_y_test, dynamic_pred5)
print("Statics Ensembel 5")
print(f"Accuracy: {accuracy5:.2f}")
print(f"Precision: {precision5:.2f}")
print(f"Recall: {recall5:.2f}") 
print(f"F1-score: {f15:.2f}")
print("Dynamics Ensembel 5")
print(f"Accuracy: {accuracy55:.2f}")
print(f"Precision: {precision55:.2f}")
print(f"Recall: {recall55:.2f}") 
print(f"F1-score: {f155:.2f}")

#Ensemble 6 : Logistic regression, GaussianNB, Random forest, C45, SVM with SMO
nb_classifier = GaussianNB()
voting6_clf = VotingClassifier(estimators=[('lr', log_reg),('nb', nb_classifier), ('rf', ran_forest), ('c45', c45), ('svm', svm_smo) ], voting='soft')
voting6_clf.fit(X_train, y_train)
voting66_clf = VotingClassifier(estimators=[('lr', log_reg),('nb', nb_classifier), ('rf', ran_forest), ('c45', c45), ('svm', svm_smo) ], voting='soft')
voting66_clf.fit(dynamic_X_train, dynamic_y_train)
static_pred6 = voting6_clf.predict(X_test)
accuracy6 = accuracy_score(y_test, static_pred6)
precision6 = precision_score(y_test, static_pred6)
recall6 = recall_score(y_test, static_pred6)
f16 = f1_score(y_test, static_pred6)
dynamic_pred6 = voting66_clf.predict(dynamic_X_test)
accuracy66 = accuracy_score(dynamic_y_test, dynamic_pred6)
precision66 = precision_score(dynamic_y_test, dynamic_pred6)
recall66 = recall_score(dynamic_y_test, dynamic_pred6)
f166 = f1_score(dynamic_y_test, dynamic_pred6)
print("Statics Ensembel 6")
print(f"Accuracy: {accuracy6:.2f}")
print(f"Precision: {precision6:.2f}")
print(f"Recall: {recall6:.2f}") 
print(f"F1-score: {f16:.2f}")
print("Dynamics Ensembel 6")
print(f"Accuracy: {accuracy66:.2f}")
print(f"Precision: {precision66:.2f}")
print(f"Recall: {recall66:.2f}") 
print(f"F1-score: {f166:.2f}")

#Ensemble 7 : SVM with SMO, logistic regression, Simple regression, AdaBoost with SVM base
knn_classifier = KNeighborsClassifier(n_neighbors=5)  # Example with k=5
voting7_clf = VotingClassifier(estimators=[('svm', svm_smo), ('lr', log_reg), ('kn', knn_classifier), ('ab', adaboost_model) ],voting='soft')
voting7_clf.fit(X_train, y_train)
voting77_clf = VotingClassifier(estimators=[('svm', svm_smo), ('lr', log_reg), ('kn', knn_classifier), ('ab', adaboost_model) ],voting='soft')
voting77_clf.fit(dynamic_X_train, dynamic_y_train)
static_pred7 = voting7_clf.predict(X_test)
accuracy7 = accuracy_score(y_test, static_pred7)
precision7 = precision_score(y_test, static_pred7)
recall7 = recall_score(y_test, static_pred7)
f17 = f1_score(y_test, static_pred7)
dynamic_pred7 = voting77_clf.predict(dynamic_X_test)
accuracy77 = accuracy_score(dynamic_y_test, dynamic_pred7)
precision77 = precision_score(dynamic_y_test, dynamic_pred7)
recall77 = recall_score(dynamic_y_test, dynamic_pred7)
f177 = f1_score(dynamic_y_test, dynamic_pred7)
print("Statics Ensembel 7")
print(f"Accuracy: {accuracy7:.2f}")
print(f"Precision: {precision7:.2f}")
print(f"Recall: {recall7:.2f}") 
print(f"F1-score: {f17:.2f}")
print("Dynamics Ensembel 7")
print(f"Accuracy: {accuracy77:.2f}")
print(f"Precision: {precision77:.2f}")
print(f"Recall: {recall77:.2f}") 
print(f"F1-score: {f177:.2f}")


#------------------------------------TEST DU LIEU MOI-----------------------------------------


#-------------------Statics-----------------


# Đường dẫn tới thư mục chứa các file APK
apk_directory = '/home/kali/NT230/RansomwareAndroid/newapk/'
# Lấy danh sách các file APK
apk_files = [os.path.join(apk_directory, f) for f in os.listdir(apk_directory) ]
# Xử lý từng file APK
results = []
for apk_file in apk_files:
    result = process_apk(apk_file)
    if result:
        results.append(result)

all_permissions = [(result['permissions']) for result in results]
apk_names = [result['apk_name'] for result in results]

new_per_vectors = [] #-------------------permission
for line in all_permissions:
    if isinstance(line, list):  # Nếu dòng là danh sách, chuyển đổi từng phần tử thành chuỗi
        line = " ".join(line)
    permissions = re.findall(r"android\.permission\.\w+", line)  # Sử dụng regex để tìm các quyền
    binary_permission_vector = create_binary_permission_vector(permissions, unique_permissions)
    new_per_vectors.append(binary_permission_vector)

binary_permission_matrix = np.array(new_per_vectors)
print("Binary Permission Vectors:", binary_permission_matrix.shape)
for vector in new_per_vectors:
    print(vector)

lines_net = [] #-----------------network
lines_text = [] #-----------------text
for result in results:
    if 'network' in result and isinstance(result['network'], list):
        lines_net.append('\n'.join(result['network']))
    if 'text' in result and isinstance(result['text'], list):
        lines_text.append('\n'.join(result['text']))

dt_net = '\n'.join(lines_net)
dt_text = '\n'.join(lines_text)

dt_net = dt_net.split('\n')
dt_text = dt_text.split('\n')

vectorizer_text = TfidfVectorizer()
X_text = vectorizer_text.fit_transform(dt_text)
# Tính TF-IDF cho các đặc trưng network
vectorizer_network = TfidfVectorizer(tokenizer=custom_tokenizer)
X_network = vectorizer_network.fit_transform(dt_net)

net_vec = vectorizer_network.idf_
text_vec = vectorizer_text.idf_
# Kết hợp các vector thành một DataFrame duy nhất
new_per_vectors_df = pd.DataFrame(new_per_vectors, columns= unique_permissions + ['label'] )
# Tạo DataFrame từ net_vec và text_vec
net_df = pd.DataFrame(net_vec.reshape(1, -1), columns=vectorizer_network.get_feature_names_out())
text_df = pd.DataFrame(text_vec.reshape(1, -1), columns=vectorizer_text.get_feature_names_out())
test_combined_df = pd.concat([new_per_vectors_df, net_df, text_df], axis=1)

print(test_combined_df)
X_test1 = test_combined_df.drop(columns=['label'])
test_imputer = SimpleImputer(strategy='mean')
X_test_imputed = test_imputer.fit_transform(X_test1)
print("asdasdasd")
print(X_test1)
print(X_test_imputed)

if set(X_test1.columns) != set(X.columns):
    print("Feature names are not consistent. Realigning columns...")
    # Realign columns to match those used during training
    new_X_aligned = X_test1.reindex(columns=X.columns, fill_value=0)  # Assuming missing features are filled with 0
    # Re-fit the imputer if necessary
    missing_features = set(X.columns).difference(X_test1.columns)
    if missing_features:
        for feature in missing_features:
            new_X_aligned[feature] = 0
        imputer.fit(X)  # Re-fit the imputer with the original training data
    # Transform the realigned data
    new_X_imputed = imputer.transform(new_X_aligned)
    print(new_X_imputed)
else:
    # Re-fit the imputer if necessary
    if not all(X.columns == X_test1.columns):
        imputer.fit(X)
    # Transform the new data
    new_X_imputed = imputer.transform(X_test1)



#--------------------------------Dynamics------------------------------


#------------------memory
# Initialize a list to store data from all files
memory_data = []

# Tạo danh sách chỉ bao gồm các file .txt
file_list = [os.path.join('/home/kali/NT230/RansomwareAndroid/Dynamics/newdata/txt', f) for f in os.listdir('/home/kali/NT230/RansomwareAndroid/Dynamics/newdata/txt') if f.endswith('.txt')]
for file_name in file_list:
    print(file_name)

for file_name in file_list:
    # Detect the encoding of the file
    with open(file_name, 'rb') as file:
        raw_data = file.read()
        result = chardet.detect(raw_data)
        encoding = result['encoding']

    # Open the file with the detected encoding
    with open(file_name, 'r', encoding=encoding, errors='ignore') as file:
        content = file.read()

    # Regular expression to match the lines of interest
    pattern = re.compile(r'(Native Heap|Dalvik Heap|Dalvik Other|Stack|Ashmem|Other dev|\.so mmap|\.apk mmap|\.ttf mmap|\.dex mmap|\.oat mmap|\.art mmap|Other mmap|Unknown|TOTAL)\s+'r'(\d+)\s+(\d+)\s+(\d+)\s+(\d+)\s*(\d*)\s*(\d*)\s*(\d*)')

    # Find all matches in the file content
    matches = pattern.findall(content)
    
    # Dictionary to hold data for this file
    csv_data = {}

    # Extract the data and handle missing values
    for entry in matches:
        name, pss, private_dirty, private_clean, swap_pss, heap_size, heap_alloc, heap_free = entry
        key_prefix = name.replace(" ", "").replace(".", "")
        csv_data[f'{key_prefix}_Pss'] = int(pss)
        csv_data[f'{key_prefix}_Private_Dirty'] = int(private_dirty)
        csv_data[f'{key_prefix}_Private_Clean'] = int(private_clean)
        csv_data[f'{key_prefix}_Swap_Pss'] = int(swap_pss)
        csv_data[f'{key_prefix}_Heap_Size'] = int(heap_size) if heap_size else 0
        csv_data[f'{key_prefix}_Heap_Alloc'] = int(heap_alloc) if heap_alloc else 0
        csv_data[f'{key_prefix}_Heap_Free'] = int(heap_free) if heap_free else 0
    
    # Append the data for this file to the list
    memory_data.append(csv_data)

# Convert the list of dictionaries to a DataFrame
mem_data_df = pd.DataFrame(memory_data)
print("________________________________-asdfgsadhfgaskdjfgasdfgsakhdfg")
print(mem_data_df)

#---------------------syscall
syscall_data = []

# Tạo danh sách chỉ bao gồm các file .csv
file_list1 = [os.path.join('/home/kali/NT230/RansomwareAndroid/Dynamics/newdata/csv', f) for f in os.listdir('/home/kali/NT230/RansomwareAndroid/Dynamics/newdata/csv') if f.endswith('.csv')]
for file_name in file_list1:
    print(file_name)

for file_name in file_list1:
    # Detect the encoding of the file
    with open(file_name, 'rb') as file:
        raw_data = file.read()
        result = chardet.detect(raw_data)
        encoding = result['encoding']

    # Open the file with the detected encoding
    with open(file_name, 'r', encoding=encoding, errors='ignore') as file:
        content = file.read()
        content = '\n'.join(line for line in content.split('\n') if not all(char == '-' or char.isspace() for char in line))
    print(content)

    pattern = r'(\d+(?:\.\d+)?)\s+(\d+(?:\.\d+)?)\s+(\d+)\s+(\d+)\s+(\d*)\s*(\S+)'

    matches = re.findall(pattern, content)
    print(matches)
    csv_data = {}


    # Extract the data and handle missing values
    for entry in matches:
        time, seconds, usecs_call, calls, errors, name = entry
        key_prefix = name.replace(" ", "").replace(".", "")
        csv_data[f'{key_prefix}_time'] = float(time)
        csv_data[f'{key_prefix}_seconds'] = float(seconds)
        csv_data[f'{key_prefix}_usecs_call'] = float(usecs_call)
        csv_data[f'{key_prefix}_calls'] = float(calls)
        csv_data[f'{key_prefix}_error'] = float(errors) if errors else 0
        

    syscall_data.append(csv_data)

# Convert the list of dictionaries to a DataFrame
syscall_data_df = pd.DataFrame(syscall_data)
# Convert the list of dictionaries to a DataFrame
print("________________________________-asdfgsadhfgaskdjfgasdfgsakhdfg")
print(syscall_data_df)
#------------------------------COMBINE FEATURE DYNAMICS--------------------

test_dynamic_combined_df = pd.concat([syscall_data_df, mem_data_df], axis=1)

print(test_dynamic_combined_df)
dynamic_X_test1 = test_dynamic_combined_df
dynamic_X_test_imputed = test_imputer.fit_transform(dynamic_X_test1)
print("asdasdasd")
print(dynamic_X_test1)
print(dynamic_X_test_imputed)

if set(dynamic_X_test1.columns) != set(dynamic_X.columns):
    print("Feature names are not consistent. Realigning columns...")
    # Realign columns to match those used during training
    dynamic_new_X_aligned = dynamic_X_test1.reindex(columns=dynamic_X.columns, fill_value=0)  # Assuming missing features are filled with 0
    # Re-fit the imputer if necessary
    missing_features1 = set(dynamic_X.columns).difference(dynamic_X_test1.columns)
    if missing_features1:
        for feature in missing_features1:
            dynamic_new_X_aligned[feature] = 0
        imputer.fit(dynamic_X)  # Re-fit the imputer with the original training data
    # Transform the realigned data
    new_dynamic_X_imputed = imputer.transform(dynamic_new_X_aligned)
    print(new_dynamic_X_imputed)
else:
    # Re-fit the imputer if necessary
    if not all(dynamic_X.columns == dynamic_X_test1.columns):
        imputer.fit(dynamic_X)
    # Transform the new data
    new_dynamic_X_imputed = imputer.transform(dynamic_X_test1)



#------------------------------Predict------------------------------


#------------Statics
statics_predictions1 = voting1_clf.predict(new_X_imputed)
print(statics_predictions1)
statics_predictions2 = voting2_clf.predict(new_X_imputed)
print(statics_predictions2)
statics_predictions3 = voting3_clf.predict(new_X_imputed)
print(statics_predictions3)
statics_predictions4 = voting4_clf.predict(new_X_imputed)
print(statics_predictions4)
statics_predictions5 = voting5_clf.predict(new_X_imputed)
print(statics_predictions5)
statics_predictions6 = voting6_clf.predict(new_X_imputed)
print(statics_predictions6)
statics_predictions7 = voting7_clf.predict(new_X_imputed)
print(statics_predictions7)
#------------Dynamics
print("**************************")
dynamics_predictions1 = voting11_clf.predict(new_dynamic_X_imputed)
print(dynamics_predictions1)
dynamics_predictions2 = voting22_clf.predict(new_dynamic_X_imputed)
print(dynamics_predictions2)
dynamics_predictions3 = voting33_clf.predict(new_dynamic_X_imputed)
print(dynamics_predictions3)
dynamics_predictions4 = voting44_clf.predict(new_dynamic_X_imputed)
print(dynamics_predictions4)
dynamics_predictions5 = voting55_clf.predict(new_dynamic_X_imputed)
print(dynamics_predictions5)
dynamics_predictions6 = voting66_clf.predict(new_dynamic_X_imputed)
print(dynamics_predictions6)
dynamics_predictions7 = voting77_clf.predict(new_dynamic_X_imputed)
print(dynamics_predictions7)


#__________________________________________Display__________________________________

if len(apk_names) == len(statics_predictions1) == len(statics_predictions2) == len(statics_predictions3) == len(statics_predictions4) == len(statics_predictions5) == len(statics_predictions6) == len(statics_predictions7):
    # Hiển thị kết quả dự đoán từ các mô hình
    print("Ensemble 1:")
    for i, apk_file in enumerate(apk_files):
        print(f"{apk_names[i]}, Predicted : {'ransomware' if statics_predictions1[i] == 1 else 'non-ransomware'}")

    print("\nEnsemble 2:")
    for j, apk_file in enumerate(apk_files):
        print(f"{apk_names[j]}, Predicted : {'ransomware' if statics_predictions2[j] == 1 else 'non-ransomware'}")
    
    print("\nEnsemble 3:")
    for k, apk_file in enumerate(apk_files):
        print(f"{apk_names[k]}, Predicted : {'ransomware' if statics_predictions3[k] == 1 else 'non-ransomware'}")
        
    print("\nEnsemble 4:")
    for h, apk_file in enumerate(apk_files):
        print(f"{apk_names[h]}, Predicted : {'ransomware' if statics_predictions4[h] == 1 else 'non-ransomware'}")
        
    print("\nEnsemble 5:")
    for g, apk_file in enumerate(apk_files):
        print(f"{apk_names[g]}, Predicted : {'ransomware' if statics_predictions5[g] == 1 else 'non-ransomware'}")
        
    print("\nEnsemble 6:")
    for f, apk_file in enumerate(apk_files):
        print(f"{apk_names[f]}, Predicted : {'ransomware' if statics_predictions6[f] == 1 else 'non-ransomware'}")
        
    print("\nEnsemble 7:")
    for l, apk_file in enumerate(apk_files):
        print(f"{apk_names[l]}, Predicted : {'ransomware' if statics_predictions7[l] == 1 else 'non-ransomware'}")


if len(file_list) == len(file_list1) == len(dynamics_predictions1) == len(dynamics_predictions2) == len(dynamics_predictions3) == len(dynamics_predictions4) == len(dynamics_predictions5) == len(dynamics_predictions6) == len(dynamics_predictions7):
    # Hiển thị kết quả dự đoán từ các mô hình
    print("Ensemble 1:")
    for i, file_name in enumerate(file_list):
        print(f"{file_name}, Predicted : {'ransomware' if dynamics_predictions1[i] == 1 else 'non-ransomware'}")

    print("\nEnsemble 2:")
    for j, file_name in enumerate(file_list):
        print(f"{file_name}, Predicted : {'ransomware' if dynamics_predictions2[j] == 1 else 'non-ransomware'}")
    
    print("\nEnsemble 3:")
    for k, file_name in enumerate(file_list):
        print(f"{file_name}, Predicted : {'ransomware' if dynamics_predictions3[k] == 1 else 'non-ransomware'}")
        
    print("\nEnsemble 4:")
    for h, file_name in enumerate(file_list):
        print(f"{file_name}, Predicted : {'ransomware' if dynamics_predictions4[h] == 1 else 'non-ransomware'}")
        
    print("\nEnsemble 5:")
    for g, file_name in enumerate(file_list):
        print(f"{file_name}, Predicted : {'ransomware' if dynamics_predictions5[g] == 1 else 'non-ransomware'}")
        
    print("\nEnsemble 6:")
    for f, file_name in enumerate(file_list):
        print(f"{file_name}, Predicted : {'ransomware' if dynamics_predictions6[f] == 1 else 'non-ransomware'}")
        
    print("\nEnsemble 7:")
    for l, file_name in enumerate(file_list):
        print(f"{file_name}, Predicted : {'ransomware' if dynamics_predictions7[l] == 1 else 'non-ransomware'}")


final_statics_predictions = []
for i in range(len(apk_files)):
    votes = [statics_predictions1[i], statics_predictions2[i], statics_predictions3[i], statics_predictions4[i], statics_predictions5[i], statics_predictions6[i], statics_predictions7[i]]
    final_statics_predict = max(set(votes), key=votes.count)  # Lớp có nhiều phiếu nhất
    final_statics_predictions.append(final_statics_predict)

final_dynamics_predictions = []
for i in range(len(file_list)):
    votes = [dynamics_predictions1[i], dynamics_predictions2[i], dynamics_predictions3[i], dynamics_predictions4[i], dynamics_predictions5[i], dynamics_predictions6[i], dynamics_predictions7[i]]
    final_dynamics_predict = max(set(votes), key=votes.count)  # Lớp có nhiều phiếu nhất
    final_dynamics_predictions.append(final_dynamics_predict)


print("\nFinal Statics Predictions:")
for i, apk_file in enumerate(apk_files):
    print(f"{apk_names[i]}, Final Predicted : {'ransomware' if final_statics_predictions[i] == 1 else 'non-ransomware'}")
print("\nFinal Dynamics Predictions:")
for i, file_name in enumerate(file_list):
    print(f"{file_name}, Final Predicted: {'ransomware' if final_dynamics_predictions[i] == 1 else 'non-ransomware'}")

def or_lists(list1, list2):
    len1 = len(list1)
    len2 = len(list2)
    # Cân bằng độ dài của hai danh sách
    if len1 > len2:
        list2 += [None] * (len1 - len2)
    elif len2 > len1:
        list1 += [None] * (len2 - len1)
   
    result = [a or b for a, b in zip(list1, list2)]
    return result


print("\nFinal Voting Predictions:")
result = or_lists(final_statics_predictions, final_dynamics_predictions)
print(result)
for i, apk_file in enumerate(apk_files):
    print(f"{apk_names[i]}, Final Predicted : {'ransomware' if result[i] == 1 else 'non-ransomware'}")
